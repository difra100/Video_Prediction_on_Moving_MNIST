{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning course 2022-2023\n",
    "## Project: Video Prediction on Moving MNIST\n",
    "### Project Contributors\n",
    "* Mattia Castelmare, 1815675\n",
    "* Andrea Giuseppe Di Francesco, 1836928\n",
    "* Enrico Fazzi, 2003876"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/tychovdo/MovingMNIST.git\n",
    "#!pip3 install pytorch-lightning==1.5.10\n",
    "# !pip3 install torchvision\n",
    "# !pip3 install matplotlib\n",
    "# !pip install wandb\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### wandb codes ###\n",
    "import wandb\n",
    "#####################\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning import Trainer\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "\n",
    "from MovingMNIST.MovingMNIST import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video(tensor):\n",
    "    ''' This function display a video, given a torch tensor (source: https://stackoverflow.com/questions/67261108/how-to-display-a-video-in-colab-using-a-pytorch-tensor-of-rgb-image-arrays)\n",
    "        INPUT: tensor (Frames x Channels x Height x Width) \n",
    "        OUTPUT: Display an animation '''\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    imgs = tensor\n",
    "    imgs = imgs.permute(0, 2, 3, 1)  # Permuting to (Bx)HxWxC format\n",
    "    frames = [[ax.imshow(imgs[i], cmap='gray')] for i in range(len(imgs))]\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, frames)\n",
    "    return ani\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    ''' This function is used within the Dataloader pytorch utility. \n",
    "        INPUT: batch: List of tuples of tensor, each tuple contains the input video and the target video, \n",
    "        OUTPUT: A tuple (input, gt), s.t. both of them has dimension (B x T x C x H x W)'''\n",
    "\n",
    "    list_tuples = list(map(lambda x: (torch.reshape(x[0], (1, x[0].shape[0], 1, x[0].shape[1], x[0].shape[2])), torch.reshape(\n",
    "        x[1], (1, x[1].shape[0], 1, x[1].shape[1], x[1].shape[2]))), batch))\n",
    "    \n",
    "    input = list_tuples[0][0]\n",
    "    gt = list_tuples[0][1]\n",
    "    \n",
    "    for i in range(1, len(list_tuples)):\n",
    "        input = torch.cat((input, list_tuples[i][0]), dim=0)\n",
    "        gt = torch.cat((gt, list_tuples[i][1]), dim = 0)\n",
    "    \n",
    "    return (input.type(torch.FloatTensor), gt.type(torch.FloatTensor))    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_train = True\n",
    "shuffle_test = False\n",
    "download = False\n",
    "\n",
    "### wandb codes ###\n",
    "wb = True\n",
    "project_name = \"VP_on_MMNIST\"\n",
    "if wb:\n",
    "    wandb.login()\n",
    "###################\n",
    "\n",
    "SEED = 2812023\n",
    "pl.seed_everything(SEED)\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch lightning DataModule:\n",
    "* Set the MMNIST Dataset object and Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pl_Dataset(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, batch_size):\n",
    "         \n",
    "         self.bs = batch_size\n",
    "\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        if stage == 'fit':\n",
    "            self.train_set = MovingMNIST(root=root,\n",
    "                        train=True,\n",
    "                        download = download)\n",
    "        elif stage == 'test':\n",
    "            self.test_set = MovingMNIST(root=root,\n",
    "                        train=False,\n",
    "                        download = download)\n",
    "            \n",
    "\n",
    "    def train_dataloader(self, *args, **kwargs):\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset = self.train_set,\n",
    "                 batch_size=self.bs,\n",
    "                 shuffle=shuffle_train,\n",
    "                 collate_fn = collate)\n",
    "\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self, *args, **kwargs):\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "                 dataset = self.test_set,\n",
    "                 batch_size=self.bs,\n",
    "                 shuffle=shuffle_test,\n",
    "                 collate_fn = collate)\n",
    "\n",
    "        return test_loader\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 1e-2\n",
    "wd = 5e-2\n",
    "\n",
    "tau = 1e-1 # KL Divergency parameter\n",
    "\n",
    "\n",
    "hyperparameters = {'lr': lr,\n",
    "                'wd': wd,\n",
    "                'epochs': 100,\n",
    "                'batch_size': batch_size\n",
    "                }\n",
    "\n",
    "data = pl_Dataset(batch_size)\n",
    "\n",
    "data.setup(stage = 'fit')\n",
    "data.setup(stage = 'test')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * 2, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(out_channels, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class RandomBaseline(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(RandomBaseline, self).__init__()\n",
    "        self.encoder = Encoder(in_channels, out_channels)\n",
    "        self.decoder = Decoder(out_channels * 2, out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "  \n",
    "        original_shape = x.shape\n",
    "     \n",
    "        x = x.reshape((original_shape[0]*original_shape[1], original_shape[2], original_shape[3], original_shape[4]))\n",
    "\n",
    "\n",
    "        x = self.encoder(x)\n",
    "   \n",
    "        \n",
    "        x = self.decoder(x)\n",
    "     \n",
    "        x = x.reshape((original_shape[0], original_shape[1], original_shape[2], original_shape[3], original_shape[4]))\n",
    "        \n",
    "\n",
    "        return x\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plTrainingModule(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        super(plTrainingModule, self).__init__()\n",
    "        self.model = model\n",
    "        self.MSE = nn.MSELoss()\n",
    "        self.KL = nn.KLDivLoss()\n",
    "        self.tot_loss_tr = []\n",
    "        self.tot_loss = []\n",
    "\n",
    "        self.KL_list = []\n",
    "        self.mse_list = []\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        ground_truth = batch[1]\n",
    "       \n",
    "        ### OUTPUT COMPUTATION ###\n",
    "       \n",
    "        prediction = self.model(batch[0])\n",
    "        KL_Loss = self.compute_KLloss(prediction, ground_truth)\n",
    "        mse = self.MSE(prediction, ground_truth)\n",
    "\n",
    "        loss = mse + KL_Loss\n",
    " \n",
    "        self.tot_loss_tr.append(loss.item())\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        ground_truth = batch[1]\n",
    "        \n",
    "        ### OUTPUT COMPUTATION ###\n",
    "\n",
    "        prediction = self.model(batch[0])\n",
    "\n",
    "        KL_Loss = self.compute_KLloss(prediction, ground_truth)\n",
    "\n",
    "        mse = self.MSE(prediction, ground_truth)\n",
    "        \n",
    "        loss = mse + KL_Loss\n",
    "        \n",
    "        self.tot_loss.append(loss.item())\n",
    "        self.KL_list.append(KL_Loss.item())\n",
    "        self.mse_list.append(mse.item())\n",
    "\n",
    "\n",
    "\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def compute_KLloss(self, predicted, ground_truth):\n",
    "\n",
    "        delta_pred = (predicted[:, 1:] - predicted[:, :-1])/tau\n",
    "        delta_gt = (ground_truth[:, 1:] - ground_truth[:, :-1])/tau\n",
    "\n",
    "        soft_pred = F.softmax(delta_pred, dim = 2) # 2 is the channel-related dimension\n",
    "        soft_gt = F.softmax(delta_gt, dim = 2) # 2 is the channel-related dimension\n",
    "\n",
    "\n",
    "\n",
    "        KL_Loss = self.KL(soft_pred, soft_gt)\n",
    "\n",
    "        return KL_Loss\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if len(self.tot_loss_tr)!= 0:\n",
    "            loss_train_mean = sum(self.tot_loss_tr)/len(self.tot_loss_tr) \n",
    "            loss_mean = sum(self.tot_loss)/len(self.tot_loss)\n",
    "            KL_mean = sum(self.KL_list)/len(self.KL_list)\n",
    "            mse_mean = sum(self.mse_list)/len(self.mse_list)\n",
    "\n",
    "            self.log(name = 'TOT. Loss on train', value = loss_train_mean)\n",
    "            self.log(name = 'TOT. Loss on test', value = loss_mean)\n",
    "            self.log(name = 'KL loss on test', value = KL_mean)\n",
    "            self.log(name = 'MSE loss on test', value = mse_mean)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.model.parameters(), lr, weight_decay = wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpu = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "model_conf = 'random'\n",
    "exp_name = model_conf + ' ' + str(hyperparameters['epochs']) + ' ' + str(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomBaseline(1, 64)\n",
    "\n",
    "\n",
    "pl_training_MDL = plTrainingModule(model)\n",
    "\n",
    "\n",
    "### WANDB CODE ###\n",
    "if wb:\n",
    "\n",
    "    wandb_logger = WandbLogger(project=project_name, name = exp_name, config = hyperparameters, entity = 'deepl_wizards')\n",
    "    trainer = pl.Trainer(\n",
    "            max_epochs = hyperparameters['epochs'],  # maximum number of epochs.\n",
    "            gpus=num_gpu,  # the number of gpus we have at our disposal.\n",
    "            default_root_dir=\"\", logger = wandb_logger        #, overfit_batches = 1\n",
    "        )\n",
    "\n",
    "else:\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = hyperparameters['epochs'],  # maximum number of epochs.\n",
    "        gpus=num_gpu,  # the number of gpus we have at our disposal.\n",
    "        default_root_dir=\"\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model = pl_training_MDL, datamodule = data)\n",
    "\n",
    "### WANDB code\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOFTMAX ISSUES\n",
    "\n",
    "delta_pred = (input[:, 1:, :, :, :] - input[:, :-1, : , :, :])/tau \n",
    "# delta_pred += 1200\n",
    "delta_gt = (gt[:, 1:, :, :, :] - gt[:, :-1, :, :, :])/tau\n",
    "# delta_gt += 1200\n",
    "soft_pred = F.softmax(delta_pred, dim = 2) # 2 is the channel-related dimension\n",
    "soft_gt = F.softmax(delta_gt, dim = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(delta_pred.to('cuda'), delta_gt.to('cuda'))\n",
    "torch.equal(soft_pred.to('cuda'), soft_gt.to('cuda'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data.train_dataloader():\n",
    "    gt = batch[1]\n",
    "    input = model(batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video(gt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video(input[0].detach())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d541b27ed3f6b3a2668175b94af942c53fef9dc2000d6033c45f742df07c856"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
