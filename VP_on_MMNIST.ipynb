{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning course 2022-2023\n",
    "## Project: Video Prediction on Moving MNIST\n",
    "### Project Contributors\n",
    "* Mattia Castelmare, 1815675\n",
    "* Andrea Giuseppe Di Francesco, 1836928\n",
    "* Enrico Fazzi, 2003876"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/tychovdo/MovingMNIST.git\n",
    "# !pip3 install pytorch-lightning==1.5.10\n",
    "# !pip3 install torchvision\n",
    "# !pip3 install matplotlib\n",
    "# !pip install wandb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### wandb codes ###\n",
    "import wandb\n",
    "#####################\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning import Trainer\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "\n",
    "from MovingMNIST.MovingMNIST import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video(tensor):\n",
    "    ''' This function display a video, given a torch tensor (source: https://stackoverflow.com/questions/67261108/how-to-display-a-video-in-colab-using-a-pytorch-tensor-of-rgb-image-arrays)\n",
    "        INPUT: tensor (Frames x Channels x Height x Width) \n",
    "        OUTPUT: Display an animation '''\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    imgs = tensor\n",
    "    imgs = imgs.permute(0, 2, 3, 1)  # Permuting to (Bx)HxWxC format\n",
    "    frames = [[ax.imshow(imgs[i], cmap='gray')] for i in range(len(imgs))]\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, frames)\n",
    "    return ani\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    ''' This function is used within the Dataloader pytorch utility. \n",
    "        INPUT: batch: List of tuples of tensor, each tuple contains the input video and the target video, \n",
    "        OUTPUT: A tuple (input, gt), s.t. both of them has dimension (B x T x C x H x W)'''\n",
    "\n",
    "    list_tuples = list(map(lambda x: (torch.reshape(x[0], (1, x[0].shape[0], 1, x[0].shape[1], x[0].shape[2])), torch.reshape(\n",
    "        x[1], (1, x[1].shape[0], 1, x[1].shape[1], x[1].shape[2]))), batch))\n",
    "    \n",
    "    input = list_tuples[0][0]\n",
    "    gt = list_tuples[0][1]\n",
    "    \n",
    "    for i in range(1, len(list_tuples)):\n",
    "        input = torch.cat((input, list_tuples[i][0]), dim=0)\n",
    "        gt = torch.cat((gt, list_tuples[i][1]), dim = 0)\n",
    "    \n",
    "    return (input.type(torch.FloatTensor), gt.type(torch.FloatTensor))    \n",
    "def save_model(checkpoint, path):\n",
    "  # This function saves a pytorch model.\n",
    "    torch.save(checkpoint, path)\n",
    "\n",
    "def load_model(path,model, device):\n",
    "  # This function loads a pytorch model from a path.\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state']) \n",
    "    \n",
    "    return checkpoint\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_train = True\n",
    "shuffle_test = False\n",
    "download = False\n",
    "\n",
    "### wandb codes ###\n",
    "wb = True\n",
    "project_name = \"VP_on_MMNIST\"\n",
    "if wb:\n",
    "    wandb.login()\n",
    "###################\n",
    "\n",
    "SEED = 2812023\n",
    "pl.seed_everything(SEED)\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch lightning DataModule:\n",
    "* Set the MMNIST Dataset object and Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pl_Dataset(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, batch_size):\n",
    "         \n",
    "         self.bs = batch_size\n",
    "\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        if stage == 'fit':\n",
    "            self.train_set = MovingMNIST(root=root,\n",
    "                        train=True,\n",
    "                        download = download)\n",
    "        elif stage == 'test':\n",
    "            self.test_set = MovingMNIST(root=root,\n",
    "                        train=False,\n",
    "                        download = download)\n",
    "            \n",
    "\n",
    "    def train_dataloader(self, *args, **kwargs):\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset = self.train_set,\n",
    "                 batch_size=self.bs,\n",
    "                 shuffle=shuffle_train,\n",
    "                 collate_fn = collate)\n",
    "\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self, *args, **kwargs):\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "                 dataset = self.test_set,\n",
    "                 batch_size=self.bs,\n",
    "                 shuffle=shuffle_test,\n",
    "                 collate_fn = collate)\n",
    "\n",
    "        return test_loader\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conf = 'simvp'\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "lr = 1e-2\n",
    "wd = 5e-2\n",
    "\n",
    "tau = 1e-1 # KL Divergency parameter\n",
    "\n",
    "\n",
    "\n",
    "### Vanilla hyperparameters ###\n",
    "if model_conf == 'random':\n",
    "    hyperparameters = {'lr': lr,\n",
    "                    'wd': wd,\n",
    "                    'epochs': 100,\n",
    "                    'batch_size': batch_size\n",
    "                    }\n",
    "elif model_conf == 'simvp':\n",
    "    hyperparameters = {'lr': lr,\n",
    "                    'wd': wd,\n",
    "                    'epochs': 100,\n",
    "                    'batch_size': batch_size\n",
    "                    }\n",
    "    CNN = {'input': 1,\n",
    "           'hidden': 16,\n",
    "           'ksize': 3,\n",
    "           'Ns': 4}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pl_Dataset(batch_size)\n",
    "\n",
    "data.setup(stage = 'fit')\n",
    "data.setup(stage = 'test')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VanillaED_1conv\n",
    "* Implementation of a simple Vanilla Encoder-Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VEncoder, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * 2, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class VDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VDecoder, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(out_channels, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class VanillaED(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VanillaED, self).__init__()\n",
    "        self.encoder = VEncoder(in_channels, out_channels)\n",
    "        self.decoder = VDecoder(out_channels * 2, out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "  \n",
    "        original_shape = x.shape\n",
    "     \n",
    "        x = x.reshape((original_shape[0]*original_shape[1], original_shape[2], original_shape[3], original_shape[4]))\n",
    "\n",
    "\n",
    "        x = self.encoder(x)\n",
    "   \n",
    "        \n",
    "        x = self.decoder(x)\n",
    "     \n",
    "        x = x.reshape((original_shape[0], original_shape[1], original_shape[2], original_shape[3], original_shape[4]))\n",
    "        \n",
    "\n",
    "        return x\n",
    "        \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SimVP\n",
    "* Implementation of the SimVP architecture, the details are available at https://arxiv.org/pdf/2206.05099.pdf,\n",
    "* Encoder (CNN) +  Translator (Inception) + Decoder (CNN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, inputC, outputC, transpose = False, groups = 8):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        if not transpose:\n",
    "            self.conv = nn.Conv2d(inputC, outputC, CNN['ksize'], padding = 'same')\n",
    "        else:\n",
    "            self.conv = nn.ConvTranspose2d(inputC, outputC, CNN['ksize'], padding = 1)\n",
    "\n",
    "        self.layernorm = nn.GroupNorm(groups, outputC)\n",
    "        self.leaky = nn.LeakyReLU(0.2, inplace = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.leaky(self.layernorm(self.conv(x)))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class EncoderSimVP(nn.Module):\n",
    "\n",
    "    def __init__(self, n_layers):\n",
    "        super(EncoderSimVP, self).__init__()\n",
    "        layers = [ConvBlock(CNN['input'], CNN['hidden'])]\n",
    "\n",
    "        for layer in range(n_layers):\n",
    "            layers.append(ConvBlock(CNN['hidden'], CNN['hidden']))\n",
    "\n",
    "        self.enc = nn.Sequential(*layers)\n",
    "\n",
    "    def forward (self, x):\n",
    "       \n",
    "        B, T, C, H, W = x.shape\n",
    "\n",
    "        x = x.reshape((B*T, C, H, W))\n",
    "\n",
    "        x = self.enc(x)\n",
    "\n",
    "        x = x.reshape((B, T, CNN['hidden'], H, W))\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "class DecoderSimVP(nn.Module):\n",
    "\n",
    "    def __init__(self, n_layers):\n",
    "        super(DecoderSimVP, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        for layer in range(n_layers):\n",
    "            layers.append(ConvBlock(CNN['hidden'], CNN['hidden'], transpose = True))\n",
    "        \n",
    "        layers.append(ConvBlock(CNN['hidden'], CNN['input'], transpose = True, groups = CNN['input']))\n",
    "\n",
    "        self.dec = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "\n",
    "        x = x.reshape((B*T, C, H, W))\n",
    "\n",
    "        x = self.dec(x)\n",
    " \n",
    "        x = x.reshape((B, T, CNN['input'], H, W))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# class InceptionModule(nn.Module):\n",
    "\n",
    "#     def __init__(self, inputC, hiddenC, kernel_list = [3, 5, 7, 11], groups = 8):\n",
    "#         super(InceptionModule, self).__init__()\n",
    "\n",
    "#         outputC = hiddenC // 2\n",
    "\n",
    "\n",
    "#         self.conv1 = nn.Conv2d()\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, C_in, C_hid, C_out, incep_ker=[3,5,7,11], groups=8):        \n",
    "        super(Inception, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(C_in, C_hid, kernel_size=1, stride=1, padding=0)\n",
    "        layers = []\n",
    "        for ker in incep_ker:\n",
    "            layers.append(ConvBlock(C_hid, C_out, ker, groups=groups))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        y = 0\n",
    "        for layer in self.layers:\n",
    "            y += layer(x)\n",
    "        return y\n",
    "    \n",
    "class Mid_Xnet(nn.Module):\n",
    "    def __init__(self, channel_in, channel_hid, N_T, incep_ker = [3,5,7,11], groups=8):\n",
    "        super(Mid_Xnet, self).__init__()\n",
    "\n",
    "        self.N_T = N_T\n",
    "        enc_layers = [Inception(channel_in, channel_hid//2, channel_hid, incep_ker= incep_ker, groups=groups)]\n",
    "        for i in range(1, N_T-1):\n",
    "            enc_layers.append(Inception(channel_hid, channel_hid//2, channel_hid, incep_ker= incep_ker, groups=groups))\n",
    "        enc_layers.append(Inception(channel_hid, channel_hid//2, channel_hid, incep_ker= incep_ker, groups=groups))\n",
    "\n",
    "        dec_layers = [Inception(channel_hid, channel_hid//2, channel_hid, incep_ker= incep_ker, groups=groups)]\n",
    "        for i in range(1, N_T-1):\n",
    "            dec_layers.append(Inception(2*channel_hid, channel_hid//2, channel_hid, incep_ker= incep_ker, groups=groups))\n",
    "        dec_layers.append(Inception(2*channel_hid, channel_hid//2, channel_in, incep_ker= incep_ker, groups=groups))\n",
    "\n",
    "        self.enc = nn.Sequential(*enc_layers)\n",
    "        self.dec = nn.Sequential(*dec_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.reshape(B, T*C, H, W)\n",
    "\n",
    "        # encoder\n",
    "        skips = []\n",
    "        z = x\n",
    "        for i in range(self.N_T):\n",
    "            z = self.enc[i](z)\n",
    "            if i < self.N_T - 1:\n",
    "                skips.append(z)\n",
    "\n",
    "        # decoder\n",
    "        z = self.dec[0](z)\n",
    "        for i in range(1, self.N_T):\n",
    "            z = self.dec[i](torch.cat([z, skips[-i]], dim=1))\n",
    "\n",
    "        y = z.reshape(B, T, C, H, W)\n",
    "        return y\n",
    "\n",
    "\n",
    "class SimVP(nn.Module):\n",
    "    def __init__(self, hid_S, hid_T=256, N_S=4, N_T=8, incep_ker=[3,5,7,11], groups=8):\n",
    "        super(SimVP, self).__init__()\n",
    "\n",
    "        self.enc = EncoderSimVP(CNN['Ns'])\n",
    "        self.hid = Mid_Xnet(10*hid_S, hid_T, N_T, incep_ker, groups)\n",
    "        self.dec = DecoderSimVP(4)\n",
    "\n",
    "\n",
    "    def forward(self, x_raw):\n",
    "        B, T, C, H, W = x_raw.shape\n",
    "        # x = x_raw.view(B*T, C, H, W)\n",
    "\n",
    "        embed = self.enc(x_raw)\n",
    "        \n",
    "        hid = self.hid(embed)\n",
    "\n",
    "        Y = self.dec(hid)\n",
    "     \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sborra = SimVP(16).to('cpu')\n",
    "# pisello = torch.randn((12, 10, 1, 64, 64), device = 'cpu')\n",
    "\n",
    "# retto = sborra(pisello)\n",
    "\n",
    "#pisello.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plTrainingModule(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        super(plTrainingModule, self).__init__()\n",
    "        self.model = model\n",
    "        self.MSE = nn.MSELoss()\n",
    "        self.KL = nn.KLDivLoss()\n",
    "        self.tot_loss_tr = []\n",
    "        self.tot_loss = []\n",
    "\n",
    "        self.KL_list = []\n",
    "        self.mse_list = []\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        ground_truth = batch[1]\n",
    "       \n",
    "        ### OUTPUT COMPUTATION ###\n",
    "       \n",
    "        prediction = self.model(batch[0])\n",
    "        #KL_Loss = self.compute_KLloss(prediction, ground_truth)\n",
    "        mse = self.MSE(prediction, ground_truth)\n",
    "\n",
    "        loss = mse #+ KL_Loss\n",
    " \n",
    "        self.tot_loss_tr.append(loss.item())\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        ground_truth = batch[1]\n",
    "        \n",
    "        ### OUTPUT COMPUTATION ###\n",
    "\n",
    "        prediction = self.model(batch[0])\n",
    "\n",
    "        #KL_Loss = self.compute_KLloss(prediction, ground_truth)\n",
    "\n",
    "        mse = self.MSE(prediction, ground_truth)\n",
    "        \n",
    "        loss = mse #+ KL_Loss\n",
    "        \n",
    "        self.tot_loss.append(loss.item())\n",
    "        # self.KL_list.append(KL_Loss.item())\n",
    "        self.mse_list.append(mse.item())\n",
    "\n",
    "\n",
    "\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def compute_KLloss(self, predicted, ground_truth):\n",
    "\n",
    "        delta_pred = (predicted[:, 1:] - predicted[:, :-1])/tau\n",
    "        delta_gt = (ground_truth[:, 1:] - ground_truth[:, :-1])/tau\n",
    "\n",
    "        soft_pred = F.softmax(delta_pred, dim = 3) # 3 is the channel-related dimension\n",
    "        soft_gt = F.softmax(delta_gt, dim = 3) # 3 is the channel-related dimension\n",
    "\n",
    "        KL_Loss = self.KL(delta_pred, delta_gt)\n",
    "\n",
    "        return KL_Loss\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if len(self.tot_loss_tr)!= 0:\n",
    "            loss_train_mean = sum(self.tot_loss_tr)/len(self.tot_loss_tr) \n",
    "            loss_mean = sum(self.tot_loss)/len(self.tot_loss)\n",
    "            # KL_mean = sum(self.KL_list)/len(self.KL_list)\n",
    "            mse_mean = sum(self.mse_list)/len(self.mse_list)\n",
    "\n",
    "            self.log(name = 'TOT. Loss on train', value = loss_train_mean)\n",
    "            self.log(name = 'TOT. Loss on test', value = loss_mean)\n",
    "            # self.log(name = 'KL loss on test', value = KL_mean)\n",
    "            self.log(name = 'MSE loss on test', value = mse_mean)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.model.parameters(), lr, weight_decay = wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpu = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "\n",
    "exp_name = model_conf + ' ' + str(hyperparameters['epochs']) + ' ' + str(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimVP(16) #VanillaED(1, 64)\n",
    "\n",
    "\n",
    "pl_training_MDL = plTrainingModule(model)\n",
    "\n",
    "\n",
    "### WANDB CODE ###\n",
    "if wb:\n",
    "\n",
    "    wandb_logger = WandbLogger(project=project_name, name = exp_name, config = hyperparameters, entity = 'deepl_wizards')\n",
    "    trainer = pl.Trainer(\n",
    "            max_epochs = hyperparameters['epochs'],  # maximum number of epochs.\n",
    "            gpus=num_gpu,  # the number of gpus we have at our disposal.\n",
    "            default_root_dir=\"\", logger = wandb_logger, callbacks=[TQDMProgressBar(refresh_rate=20)]        #, overfit_batches = 1\n",
    "        )\n",
    "\n",
    "else:\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = hyperparameters['epochs'],  # maximum number of epochs.\n",
    "        gpus=num_gpu,  # the number of gpus we have at our disposal.\n",
    "        default_root_dir=\"\", callbacks=[TQDMProgressBar(refresh_rate=20)]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model = pl_training_MDL, datamodule = data)\n",
    "\n",
    "### WANDB code\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOFTMAX ISSUES\n",
    "\n",
    "delta_pred = (output[:, 1:, :, :, :] - output[:, :-1, : , :, :])/tau \n",
    "# delta_pred += 1200\n",
    "delta_gt = (gt[:, 1:, :, :, :] - gt[:, :-1, :, :, :])/tau\n",
    "# delta_gt += 1200\n",
    "soft_pred = F.softmax(delta_pred, dim = 3) # 2 is the channel-related dimension\n",
    "soft_gt = F.softmax(delta_gt, dim = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = SimVP(16)\n",
    "load_model('simvp.pt', mod, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(delta_pred.to('cuda'), delta_gt.to('cuda'))\n",
    "torch.equal(soft_pred.to('cuda'), soft_gt.to('cuda'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data.val_dataloader():\n",
    "    gt = batch[1]\n",
    "    output = mod(batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video(gt[1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video(output[1].cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video(batch[0][0].detach())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d541b27ed3f6b3a2668175b94af942c53fef9dc2000d6033c45f742df07c856"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
